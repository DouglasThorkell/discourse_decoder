{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmmA6Pevc-ra"
      },
      "source": [
        "## Description of Project\n",
        "\n",
        "[Study from Google Deepmind]\n",
        "https://www.nature.com/articles/d41586-024-03424-z\n",
        "\n",
        "You need to use:\n",
        "\n",
        "- Effective Prompt Engineering\n",
        "- Langchain\n",
        "- Rag\n",
        "- AI Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ok_BTbnWOuZ"
      },
      "source": [
        "# Discourse Decoder\n",
        "\n",
        "**Summarized Idea**: Article-Based AI Debate Platform with Common Ground Identification\n",
        "\n",
        "**Core Concept**\n",
        "\n",
        "A platform where users upload an article they agree or disagree with and engage in an AI-driven debate. The system extracts key arguments from the article, debates the user’s perspective against it, and highlights areas where opposing views are most likely to find common ground.\n",
        "\n",
        "**Features**\n",
        "\n",
        "Article Upload and Analysis:\n",
        "\n",
        "Users can upload text, PDFs, or URLs. The platform extracts main arguments and evidence using LLMs.\n",
        "\n",
        "AI-Driven Debate:\n",
        "\n",
        "*   *Advocate Agent*: Defends the article’s stance.\n",
        "*   *User-Aligned Agent*: Argues for the user's perspective.\n",
        "*   *Moderator Agent*: Ensures structured debate flow.\n",
        "\n",
        "Common Ground Identification:\n",
        "\n",
        "*   Semantic analysis detects shared themes or goals.\n",
        "*   Suggestions for reconciling differences are generated (e.g., compromises or actionable solutions).\n",
        "\n",
        "Interactive Features:\n",
        "- Post-debate summaries, including:\n",
        " * Key points from both sides.\n",
        " * Overlapping themes (common ground).\n",
        " * Suggested reconciliation strategies.\n",
        "\n",
        "Visual Outputs:\n",
        "\n",
        "* Venn Diagrams: Show agreement and divergence.\n",
        "* Actionable Insights: Highlight compromises based on common ground.\n",
        "\n",
        "Technologies:\n",
        "\n",
        "* Prompt Engineering: For argument extraction and structured debate.\n",
        "* LangChain: Orchestrates multi-agent interactions and workflows.\n",
        "* RAG (Retrieval-Augmented Generation): Enhances arguments with external evidence.\n",
        "* Semantic Analysis: Detects thematic overlaps using embeddings (e.g., OpenAI or Pinecone).\n",
        "* AI Agents\n",
        "\n",
        "**Value Proposition**\n",
        "\n",
        "1.   Critical Thinking: Helps users challenge or reinforce their beliefs.\n",
        "2.   Consensus Building: Moves beyond debate to suggest actionable compromises.\n",
        "3.   Portfolio Appeal: Demonstrates mastery of LLMs, LangChain, RAG, and user-centered design.\n",
        "\n",
        "This project combines AI-driven argumentation with reconciliation, making it a standout tool for education, media literacy, and professional negotiation.\n",
        "\n",
        "**Tested Links**\n",
        "\n",
        "https://www.theguardian.com/commentisfree/2024/nov/30/wicked-would-be-fun-and-forgettable-but-for-the-alt-right-waging-dark-arts-against-it\n",
        "\n",
        "https://www.usatoday.com/story/opinion/2019/05/22/alabama-abortion-ban-protect-both-women-and-unborn-column/3738904002/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gIPAYRkGqbqh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -qU crewai crewai_tools langchain langchain-openai sentence-transformers streamlit faiss-gpu httpx pypdf unstructured pypandoc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('openai_api_key')\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('serper_api_key')"
      ],
      "metadata": {
        "id": "VkmUrIgR6Jwc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile discoursedecoder.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "from langchain.schema import Document\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "import re\n",
        "\n",
        "## LLM initialization Function ##\n",
        "def get_llm(temperature, model):\n",
        "    my_api_key = os.environ.get('openai_api_key')\n",
        "    return ChatOpenAI(\n",
        "        api_key=my_api_key,\n",
        "        model_name=model,\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "## Get Valid URL Function ##\n",
        "def get_valid_url():\n",
        "    url = st.text_input(\"Enter the URL of a webpage: \").strip()\n",
        "    if not url:\n",
        "        return None\n",
        "    if not re.match(r'^https?://', url):\n",
        "        st.error(\"Invalid URL. Please ensure it starts with http or https.\")\n",
        "        return None\n",
        "    return url\n",
        "\n",
        "## Fetch URL Function ##\n",
        "def fetch_url_content(url, retries=3, backoff_factor=1):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            return response.text\n",
        "        except requests.RequestException as e:\n",
        "            st.warning(f\"**Attempt {attempt + 1}/{retries} failed:** {e}\")\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(backoff_factor * (2 ** attempt))\n",
        "            else:\n",
        "                st.error(\"**Error fetching the URL:** All attempts failed. Please check the URL or try again later.\")\n",
        "                return None\n",
        "\n",
        "## Paragraph Based Chunking Function ##\n",
        "def paragraph_based_chunking(raw_text, max_chunk_size=3000, overlap=500):\n",
        "    paragraphs = raw_text.split(\"\\n\\n\")\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        if len(current_chunk) + len(paragraph) <= max_chunk_size:\n",
        "            current_chunk += paragraph + \"\\n\\n\"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = paragraph[-overlap:] + paragraph\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return [Document(page_content=chunk) for chunk in chunks]\n",
        "\n",
        "## Initializing Retrieval Chain Function ##\n",
        "def initialize_retrieval_chain_from_text(raw_text):\n",
        "    chunks = paragraph_based_chunking(raw_text)\n",
        "\n",
        "    openai_api_key = os.environ.get('openai_api_key')\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "    llm = get_llm(temperature=0.7, model=\"gpt-4o-mini\")\n",
        "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "    crchain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=retriever,\n",
        "        memory=memory\n",
        "    )\n",
        "    return crchain\n",
        "\n",
        "## Extracting Main Arguments Function ##\n",
        "def extract_main_arguments(retrieval_chain):\n",
        "    prompt = (\n",
        "        \"Summarize the main argument in the document in 100 words or less.\"\n",
        "        \"Your summary should:\"\n",
        "        \"Start with the title of the article in bold and within quotation marks, followed by a blank line.\"\n",
        "        \"Highlight the core claims made by the author.\"\n",
        "        \"Include the key evidence or examples that support these claims.\"\n",
        "        \"Use formal, objective language. Begin with an introductory sentence that captures the essence of the article, \"\n",
        "        \"followed by the supporting points and conclusion. For example:\"\n",
        "        \"'The article argues that [main argument], supported by [key evidence]. It concludes by [conclusion].'\"\n",
        "    )\n",
        "\n",
        "    result = retrieval_chain({\"question\": prompt})\n",
        "\n",
        "    return result[\"answer\"]\n",
        "\n",
        "## Extracting Three Stances Function ##\n",
        "def extract_three_stances(retrieval_chain):\n",
        "    prompts = {\n",
        "        \"supportive\": \"Create a user-centered statement that supports the argument in the article.\"\n",
        "                      \"It should be a simple stance that is easily differentiated from other viewpoints.\"\n",
        "                      \"Your answer should be concise and within quotation marks. You are the user.\"\n",
        "                      \"For example, say: 'I am pro-choice, which means I believe that a woman has the right to make decisions about her own body without interference, including the choice to have an abortion.'\"\n",
        "                      \"Start with: 'I am', 'I believe', or 'I think'.\"\n",
        "                      \"Your answer should be around 30 words.\",\n",
        "        \"opposing\": \"Create a user-centered statement that opposes the argument in the article.\"\n",
        "                    \"It should be a simple stance that is easily differentiated from other viewpoints.\"\n",
        "                    \"Your answer should be concise and within quotation marks. You are the user.\"\n",
        "                    \"For example, say: 'I am pro-choice, which means I believe that a woman has the right to make decisions about her own body without interference, including the choice to have an abortion.'\"\n",
        "                     \"Start with: 'I am', 'I believe', or 'I think'.\"\n",
        "                     \"Your answer should be around 30 words.\",\n",
        "        \"middle\": \"Create a user-centered statement that niether supports nor opposes the argument in the article.\"\n",
        "                  \"It should be a simple stance that cannot decide between a supportive or an opposing view of the article.\"\n",
        "                  \"Your answer should be concise and within quotation marks. You are the user.\"\n",
        "                  \"For example, say: 'I am pro-choice, which means I believe that a woman has the right to make decisions about her own body without interference, including the choice to have an abortion.'\"\n",
        "                  \"Start with: 'I am', 'I believe', or 'I think'.\"\n",
        "                  \"Your answer should be around 30 words.\",\n",
        "    }\n",
        "\n",
        "    fallback_responses = {\n",
        "        \"supportive\": '\"I believe there are strong points in the article’s perspective that deserve further exploration, and I generally lean toward agreeing with its stance.\"',\n",
        "        \"opposing\": '\"I believe there are valid concerns about the arguments presented, and I am inclined to challenge its conclusions.\"',\n",
        "        \"middle\": '\"I believe it’s important to consider all sides of the discussion, and I find myself seeing value in multiple perspectives without fully committing to one.\"'\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for key, prompt in prompts.items():\n",
        "        response = retrieval_chain({\"question\": prompt})[\"answer\"]\n",
        "        st.write(f\"Raw Response for `{key}`: {response}\")\n",
        "\n",
        "        if \":\" in response and response.lower().startswith(\"a user-centered statement\"):\n",
        "            response = response.split(\":\", 1)[-1].strip()\n",
        "        cleaned_response = response.strip().strip('\"')\n",
        "\n",
        "        if \"I don't know\" in response or cleaned_response.startswith(\"The\") or cleaned_response.startswith(\"While\"):\n",
        "            results[key] = fallback_responses[key]\n",
        "        else:\n",
        "            results[key] = f'\"{cleaned_response}\"'\n",
        "\n",
        "    return {\"pro\": results[\"supportive\"], \"con\": results[\"opposing\"], \"middle\": results[\"middle\"]}\n",
        "\n",
        "## OpenAI API ##\n",
        "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
        "os.environ['openai_api_key'] = openai_api_key\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4o-mini'\n",
        "\n",
        "## Serper API ##\n",
        "serper_api_key = os.environ.get('SERPER_API_KEY')\n",
        "os.environ[\"SERPER_API_KEY\"] = serper_api_key\n",
        "\n",
        "search_tool = SerperDevTool()\n",
        "scrape_tool = ScrapeWebsiteTool()\n",
        "\n",
        "## Supporting Argument Crew ##\n",
        "supporting_writer = Agent(\n",
        "    role=\"Supporting Writer\",\n",
        "    goal=\"Develop a concise argument supporting {topic}.\",\n",
        "    backstory=\"You are tasked with crafting a clear, persuasive argument in favor of {topic}.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=False\n",
        ")\n",
        "supporting_researcher = Agent(\n",
        "    role=\"Supporting Researcher\",\n",
        "    goal=\"Provide relevant evidence supporting {topic} to strengthen the Writer's argument.\",\n",
        "    backstory=\"You expand the Writer's argument by finding relevant examples, statistics, or case studies.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=False,\n",
        "    tools=[search_tool, scrape_tool]\n",
        ")\n",
        "supporting_debater = Agent(\n",
        "    role=\"Supporting Debater\",\n",
        "    goal=\"Combine the Writer's argument and the Researcher's evidence into a clear, final 100-word argument supporting {topic}.\",\n",
        "    backstory=\"You are responsible for presenting the Supporting Crew's final argument in a concise and compelling manner.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=False\n",
        ")\n",
        "supporting_writer_task = Task(\n",
        "    description=\"Draft a clear, persuasive argument in favor of {topic} that is concise and provides a foundation for adding supporting evidence. Address any questions posed by the Moderator Crew: {moderator_question}.\",\n",
        "    expected_output=\"A concise argument supporting {topic} that the Researcher can expand on with evidence.\",\n",
        "    agent=supporting_writer,\n",
        "    async_execution=True\n",
        ")\n",
        "supporting_researcher_task = Task(\n",
        "    description= \"Expand on the Writer's argument with evidence such as statistics, examples, or case studies \"\n",
        "                 \"that support {topic}. Use the search tool or scrape tool to find supporting evidence on the topic {topic}. \"\n",
        "                 \"Choose the most relevant source for high-quality evidence.\"\n",
        "                 \"Ensure the evidence addresses any questions posed by the Moderator Crew: {moderator_question}.\",\n",
        "    expected_output=\"Relevant evidence in text form that strengthens the Writer's argument.\",\n",
        "    agent=supporting_researcher,\n",
        "    async_execution=True\n",
        ")\n",
        "supporting_debater_task = Task(\n",
        "    description=\"Combine the Writer's argument and the Researcher's evidence to create a 100-word final argument supporting {topic}. Ensure the argument addresses any questions posed by the Moderator Crew: {moderator_question}.\",\n",
        "    expected_output=\"A finalized, polished 100-word argument supporting {topic}.\",\n",
        "    agent=supporting_debater\n",
        ")\n",
        "supporting_crew = Crew(\n",
        "    agents=[supporting_writer, supporting_researcher, supporting_debater],\n",
        "    tasks=[supporting_writer_task, supporting_researcher_task, supporting_debater_task],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "## Opposing Argument Crew ##\n",
        "opposing_writer = Agent(\n",
        "    role=\"Opposing Writer\",\n",
        "    goal=\"Develop a concise counterargument against {topic}, responding directly to the Supporting Crew's argument: {supporting_argument}.\",\n",
        "    backstory=\"You are tasked with crafting a strong counterargument based on the Supporting Crew's argument.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=False\n",
        ")\n",
        "opposing_researcher = Agent(\n",
        "    role=\"Opposing Researcher\",\n",
        "    goal=\"Provide relevant evidence opposing {topic}, directly addressing the Supporting Crew's argument: {supporting_argument}.\",\n",
        "    backstory=\"You expand the Writer's counterargument by finding evidence, examples, or statistics that directly challenge the Supporting Crew's points.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=False,\n",
        "    tools=[search_tool, scrape_tool]\n",
        ")\n",
        "opposing_debater = Agent(\n",
        "    role=\"Opposing Debater\",\n",
        "    goal=\"Combine the Writer's counterargument and the Researcher's evidence into a clear, final 100-word argument opposing {topic}.\",\n",
        "    backstory=\"You are responsible for presenting the Opposing Crew's final argument in a concise and compelling manner.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=False\n",
        ")\n",
        "opposing_writer_task = Task(\n",
        "    description=\"Draft a clear counterargument opposing {topic} that directly addresses the Supporting Crew's argument: {supporting_argument}. Also, address any questions posed by the Moderator Crew: {moderator_question}.\",\n",
        "    expected_output=\"A concise counterargument opposing {topic} that the Researcher can expand on with evidence.\",\n",
        "    agent=opposing_writer,\n",
        "    async_execution=True\n",
        ")\n",
        "opposing_researcher_task = Task(\n",
        "    description=\"Expand on the Writer's counterargument with evidence such as statistics, examples, or case studies that challenge the Supporting Crew's argument: {supporting_argument}.\"\n",
        "                \"Use the search tool or scrape tool to find supporting evidence on the topic {topic}. \"\n",
        "                \"Choose the most relevant source for high-quality evidence.\"\n",
        "                \"Ensure the evidence also addresses any questions posed by the Moderator Crew: {moderator_question}.\",\n",
        "    expected_output=\"Relevant evidence in text form that strengthens the Writer's counterargument.\",\n",
        "    agent=opposing_researcher,\n",
        "    async_execution=True\n",
        ")\n",
        "opposing_debater_task = Task(\n",
        "    description=\"Combine the Writer's counterargument and the Researcher's evidence to create a 100-word final argument opposing {topic}. Ensure the argument addresses any questions posed by the Moderator Crew: {moderator_question}.\",\n",
        "    expected_output=\"A finalized, polished 100-word counterargument opposing {topic}.\",\n",
        "    agent=opposing_debater\n",
        ")\n",
        "opposing_crew = Crew(\n",
        "    agents=[opposing_writer, opposing_researcher, opposing_debater],\n",
        "    tasks=[opposing_writer_task, opposing_researcher_task, opposing_debater_task],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "## Moderator Crew ##\n",
        "moderator = Agent(\n",
        "    role=\"Moderator\",\n",
        "    goal=\"Provide a 100-word summary evaluating arguments from both Supporting and Opposing Crews.\",\n",
        "    backstory=\"You impartially summarize the round, considering the Supporting Crew's argument: {supporting_argument} and the Opposing Crew's counterargument: {opposing_argument}.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=False\n",
        ")\n",
        "question_analyst = Agent(\n",
        "    role=\"Question Analyst\",\n",
        "    goal=\"Pose a neutral question addressing both crews' arguments: {supporting_argument} and {opposing_argument}, unless it is the last round.\",\n",
        "    backstory=\"You generate a question to deepen the discussion based on the arguments presented by both crews unless it is the last round.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=False\n",
        ")\n",
        "summary_writer = Agent(\n",
        "    role=\"Summary Writer\",\n",
        "    goal=\"Craft a 100-word reflection summarizing the key points from the round and explicitly include the question generated by the Question Analyst unless it is the last round.\",\n",
        "    backstory=\"You produce a concise summary based on the Supporting Crew's argument: {supporting_argument}, the Opposing Crew's counterargument: {opposing_argument}, and the question generated by the Question Analyst unless it is the last round.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=False\n",
        ")\n",
        "moderator_task = Task(\n",
        "    description=\"Summarize and reflect on arguments from both crews: {supporting_argument} and {opposing_argument} in 100 words. Include the question generated by the Question Analyst at the end of the summary unless it's the last round.\",\n",
        "    expected_output=\"100-word neutral summary including the question generated by the Question Analyst.\",\n",
        "    agent=moderator\n",
        ")\n",
        "question_analyst_task = Task(\n",
        "    description=\"Generate a neutral question based on arguments presented: {supporting_argument} and {opposing_argument}, unless it is the last round.\",\n",
        "    expected_output=\"A neutral, thought-provoking question based on the arguments.\",\n",
        "    agent=question_analyst\n",
        ")\n",
        "summary_writer_task = Task(\n",
        "    description=(\n",
        "        \"Produce a concise reflection summarizing the key points from the Supporting Crew ({supporting_argument}) \"\n",
        "        \"and Opposing Crew ({opposing_argument}). Include the question generated by the Question Analyst at the end \"\n",
        "        \"of your output explicitly labeled as '**Moderator's Question:**'.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"100-word summary of the debate round, with the question appended as '**Moderator's Question:**', unless it is the last round.\"\n",
        "    ),\n",
        "    agent=summary_writer\n",
        ")\n",
        "moderation_crew = Crew(\n",
        "    agents=[moderator, question_analyst, summary_writer],\n",
        "    tasks=[moderator_task, question_analyst_task, summary_writer_task],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "## Finding Common Ground Function ##\n",
        "def find_common_ground_debate(supporting_arguments, opposing_arguments, similarity_threshold=0.7):\n",
        "    if not supporting_arguments or not opposing_arguments:\n",
        "        return \"No significant common ground could be identified across the debate rounds.\"\n",
        "\n",
        "    ## Sentence Transformer Model ##\n",
        "    try:\n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    except Exception as e:\n",
        "        return f\"Error loading model: {str(e)}\"\n",
        "\n",
        "    all_supporting_sentences = []\n",
        "    all_opposing_sentences = []\n",
        "    for round_num, (supporting, opposing) in enumerate(zip(supporting_arguments, opposing_arguments), 1):\n",
        "        all_supporting_sentences += [\n",
        "            f\"Round {round_num}: {sentence}\" for sentence in supporting.split(\". \") if sentence\n",
        "        ]\n",
        "        all_opposing_sentences += [\n",
        "            f\"Round {round_num}: {sentence}\" for sentence in opposing.split(\". \") if sentence\n",
        "        ]\n",
        "\n",
        "    try:\n",
        "        supporting_embeddings = model.encode(all_supporting_sentences, convert_to_tensor=True)\n",
        "        opposing_embeddings = model.encode(all_opposing_sentences, convert_to_tensor=True)\n",
        "    except Exception as e:\n",
        "        return f\"Error computing embeddings: {str(e)}\"\n",
        "\n",
        "    similarity_matrix = util.cos_sim(supporting_embeddings, opposing_embeddings)\n",
        "\n",
        "    common_ground_pairs = []\n",
        "    for i, supporting_sentence in enumerate(all_supporting_sentences):\n",
        "        for j, opposing_sentence in enumerate(all_opposing_sentences):\n",
        "            if similarity_matrix[i][j] >= similarity_threshold:\n",
        "                pair = (\n",
        "                    supporting_sentence.split(\": \")[-1],\n",
        "                    opposing_sentence.split(\": \")[-1],\n",
        "                    similarity_matrix[i][j].item()\n",
        "                )\n",
        "                common_ground_pairs.append(pair)\n",
        "\n",
        "    if common_ground_pairs:\n",
        "        themes = [pair[0] for pair in common_ground_pairs]\n",
        "        unique_themes = list(set(themes))\n",
        "\n",
        "        llm = get_llm(temperature=0.7, model=\"gpt-4o-mini\")\n",
        "\n",
        "        prompt = (\n",
        "            \"The following are themes of agreement identified across multiple debate rounds:\\n\\n\"\n",
        "            + \"\\n\".join(f\"- {theme}\" for theme in unique_themes)\n",
        "            + \"\\n\\n\"\n",
        "            \"Based on these identified themes, craft a cohesive and concise statement summarizing the common ground between opposing views. Your summary should:\"\n",
        "            \"Clearly articulate the shared principles or areas of agreement.\"\n",
        "            \"Acknowledge the distinctions or key differences in the opposing perspectives.\"\n",
        "            \"Explain how the common ground perspective incorporates elements from both sides to foster a unified understanding.\"\n",
        "            \"Use formal, balanced language and avoid overly technical jargon. Ensure the statement is clear, actionable, and limited to 100 words.\"\n",
        "            \"For example: 'Despite differing views on [opposing points], both sides agree on [common principles]. This shared understanding emphasizes [implication of agreement].'\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            messages = [\n",
        "                SystemMessage(content=\"You are an AI assistant that helps find common ground.\"),\n",
        "                HumanMessage(content=prompt),\n",
        "            ]\n",
        "            response = llm(messages)\n",
        "\n",
        "            if hasattr(response, \"content\"):\n",
        "                return response.content\n",
        "            elif isinstance(response, str):\n",
        "                return response\n",
        "            else:\n",
        "                return \"Unexpected response format from the LLM.\"\n",
        "        except Exception as e:\n",
        "            return f\"Error generating response from LLM: {str(e)}\"\n",
        "    else:\n",
        "        return \"No significant common ground could be identified across the debate rounds.\"\n",
        "\n",
        "## Final Insight Function ##\n",
        "def generate_final_insight(common_ground):\n",
        "    if \"common_ground\" not in st.session_state:\n",
        "        st.session_state.common_ground = None\n",
        "\n",
        "    if \"No significant common ground\" in common_ground:\n",
        "        return (\n",
        "            \"Based on the debate, no significant overlaps were identified. This indicates \"\n",
        "            \"strongly polarized views, and further discussion may require finding shared \"\n",
        "            \"underlying values or fostering a deeper dialogue.\"\n",
        "        )\n",
        "\n",
        "    if not common_ground or not isinstance(common_ground, str) or not common_ground.strip():\n",
        "        return \"Error: Invalid common ground input.\"\n",
        "\n",
        "    try:\n",
        "        llm = get_llm(temperature=0.7, model=\"gpt-4o-mini\")\n",
        "    except Exception as e:\n",
        "        return f\"Error initializing the LLM: {str(e)}\"\n",
        "\n",
        "    prompt = (\n",
        "        f\"The following statement summarizes the common ground across multiple debate rounds:\\n\\n\"\n",
        "        f\"{common_ground}\\n\\n\"\n",
        "        \"Using the identified common ground, provide practical suggestions for an individual moving forward.\"\n",
        "        \"Your recommendations should:\"\n",
        "        \"Be tailored to the themes in the common ground statement.\"\n",
        "        \"Focus on impactful words and actions that the individual can take to foster understanding and reconciliation.\"\n",
        "        \"Use a direct tone, addressing the individual as 'you.'\"\n",
        "        \"End with a specific recommendation for how the individual should engage when discussing the topic with someone who holds an opposing viewpoint.\"\n",
        "        \"Begin this final sentence with: 'When talking to someone about [topic], you should...'\"\n",
        "        \"Limit your response to 50 words and ensure it is concise, actionable, and user-centered.\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        from langchain.schema import HumanMessage\n",
        "\n",
        "        messages = [\n",
        "            HumanMessage(content=prompt)\n",
        "        ]\n",
        "        response = llm(messages)\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response from LLM: {str(e)}\"\n",
        "\n",
        "    if hasattr(response, \"content\"):\n",
        "        final_insight = response.content\n",
        "    elif isinstance(response, str):\n",
        "        final_insight = response\n",
        "    else:\n",
        "        final_insight = \"Unexpected response format from the LLM.\"\n",
        "\n",
        "    return final_insight\n",
        "\n",
        "## Main Function ##\n",
        "def main():\n",
        "\n",
        "    st.title(\"Discourse Decoder\")\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.title(\"About\")\n",
        "        st.markdown(\n",
        "\n",
        "            \"\"\"\n",
        "            **Discourse Decoder** is a tool designed to analyze and break down arguments from online content.\n",
        "\n",
        "            **It Helps You**:\n",
        "\n",
        "            - Extract main arguments from a webpage.\n",
        "            - Dynamically engage in debates with supportive, opposing, and neutral perspectives.\n",
        "            - Identify common ground and actionable insights.\n",
        "\n",
        "            **How It Works:**\n",
        "\n",
        "            1. Paste the URL of a webpage into the input field above.\n",
        "            2. Wait for the application to fetch and analyze the content.\n",
        "            3. Review the article arguments and select a stance to simulate a debate.\n",
        "            4. See how the debate unfolds.\n",
        "            5. Review the common ground and find actionable insights.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    ## Step 1: Getting a valid URL from the user ##\n",
        "    url = get_valid_url()\n",
        "    if not url:\n",
        "        return\n",
        "\n",
        "    ## Step 2: Fetching content from the URL ##\n",
        "    with st.spinner(\"Fetching content...\"):\n",
        "        raw_content = fetch_url_content(url)\n",
        "    if not raw_content:\n",
        "        st.error(\"Failed to fetch content from the URL. Exiting...\")\n",
        "        return\n",
        "    st.success(\"Content fetched successfully!\")\n",
        "\n",
        "    ## Step 3: Initializing retrieval chain ##\n",
        "    retrieval_chain = initialize_retrieval_chain_from_text(raw_content)\n",
        "\n",
        "    ## Step 4: Extracting main arguments dynamically ##\n",
        "    if \"article_arguments\" not in st.session_state:\n",
        "        with st.spinner(\"Extracting arguments...\"):\n",
        "            st.session_state.article_arguments = extract_main_arguments(retrieval_chain)\n",
        "    st.subheader(\"Article\")\n",
        "    st.markdown(f\"{st.session_state.article_arguments}\")\n",
        "\n",
        "    ## Step 5: Extracting stances dynamically ##\n",
        "    if \"stances\" not in st.session_state:\n",
        "        with st.spinner(\"Extracting stances...\"):\n",
        "            st.session_state.stances = extract_three_stances(retrieval_chain)\n",
        "\n",
        "    stances = st.session_state.stances\n",
        "\n",
        "    st.subheader(\"Select a stance\")\n",
        "    st.markdown(\"Select a stance based on the analysis:\")\n",
        "    st.markdown(f\"1. **Supportive:** {stances['pro']}\")\n",
        "    st.markdown(f\"2. **Opposing:** {stances['con']}\")\n",
        "    st.markdown(f\"3. **Neutral:** {stances['middle']}\")\n",
        "\n",
        "    user_choice = st.radio(\"Enter the number of your choice:\", [\"1\", \"2\", \"3\"])\n",
        "\n",
        "    if st.button(\"Confirm Choice\"):\n",
        "        st.session_state.user_stance = (\n",
        "            stances[\"pro\"] if user_choice == \"1\" else stances[\"con\"] if user_choice == \"2\" else stances[\"middle\"]\n",
        "        )\n",
        "        st.success(f\"You selected: {st.session_state.user_stance}\")\n",
        "\n",
        "        ## Step 6: Debate Simulation ##\n",
        "        st.subheader(\"Debate Simulation\")\n",
        "\n",
        "        moderator_question = None\n",
        "        debate_transcript = []\n",
        "        supporting_arguments = []\n",
        "        opposing_arguments = []\n",
        "\n",
        "        for round_num in range(1, 4):\n",
        "            with st.expander(f\"Round {round_num}\", expanded=True):\n",
        "                st.markdown(f\"### **Round {round_num}**\")\n",
        "\n",
        "                with st.spinner(f\"Processing Round {round_num}...\"):\n",
        "\n",
        "                    ## Supporting Argument Crew ##\n",
        "                    supporting_inputs = {\n",
        "                        \"topic\": st.session_state.article_arguments,\n",
        "                        \"objective\": \"Highlight the benefits\",\n",
        "                        \"moderator_question\": moderator_question or \"\"\n",
        "                    }\n",
        "                    if round_num > 1:\n",
        "                        supporting_inputs[\"opposing_arguments\"] = opposing_result.raw\n",
        "                    supporting_result = supporting_crew.kickoff(supporting_inputs)\n",
        "                    supporting_arguments.append(supporting_result.raw.strip())\n",
        "\n",
        "                    ## Opposing Argument Crew ##\n",
        "                    opposing_inputs = {\n",
        "                        \"topic\": st.session_state.user_stance,\n",
        "                        \"objective\": \"Highlight the risks\",\n",
        "                        \"supporting_argument\": supporting_result.raw,\n",
        "                        \"moderator_question\": moderator_question or \"\"\n",
        "                    }\n",
        "                    opposing_result = opposing_crew.kickoff(opposing_inputs)\n",
        "                    opposing_arguments.append(opposing_result.raw.strip())\n",
        "\n",
        "                    ## Moderator Crew ##\n",
        "                    moderation_inputs = {\n",
        "                        \"topic\": st.session_state.article_arguments,\n",
        "                        \"supporting_argument\": supporting_result.raw,\n",
        "                        \"opposing_argument\": opposing_result.raw\n",
        "                    }\n",
        "                    moderation_result = moderation_crew.kickoff(moderation_inputs)\n",
        "\n",
        "                    if round_num <= 3 and \"**Moderator's Question:**\" in moderation_result.raw:\n",
        "                        moderator_question = moderation_result.raw.split(\"**Moderator's Question:**\")[-1].strip()\n",
        "                    else:\n",
        "                        moderator_question = None\n",
        "\n",
        "                    moderator_output_clean = moderation_result.raw.replace(\n",
        "                        f\"**Moderator's Question:** {moderator_question}\", \"\").strip()\n",
        "\n",
        "                    col1, col2 = st.columns(2)\n",
        "\n",
        "                    with col1:\n",
        "                        st.markdown(\"#### **Article View**\")\n",
        "                        st.markdown(f\"> {supporting_result.raw.strip()}\")\n",
        "\n",
        "                    with col2:\n",
        "                        st.markdown(\"#### **Your View**\")\n",
        "                        st.markdown(f\"> {opposing_result.raw.strip()}\")\n",
        "\n",
        "                    st.markdown(\"#### **Moderator's Perspective**\")\n",
        "                    st.markdown(f\"{moderator_output_clean}\")\n",
        "\n",
        "                    debate_transcript.append(f\"**Round {round_num}**\")\n",
        "                    debate_transcript.append(f\"**Supporting View:** {supporting_result.raw.strip()}\")\n",
        "                    debate_transcript.append(f\"**Opposing View:** {opposing_result.raw.strip()}\")\n",
        "                    debate_transcript.append(f\"**Moderator View:** {moderator_output_clean}\")\n",
        "\n",
        "                    if round_num < 3:\n",
        "                        debate_transcript.append(f\"**Moderator's Question for Next Round:** {moderator_question}\")\n",
        "                        st.markdown(f\"#### **Moderator's Question for Next Round**\")\n",
        "                        st.markdown(f\"{moderator_question}\")\n",
        "\n",
        "        ## Step 7: Find Common Ground ##\n",
        "        st.subheader(\"Potential Avenues for Reconciliation\")\n",
        "        with st.spinner(\"Analyzing common ground...\"):\n",
        "            common_ground = find_common_ground_debate(supporting_arguments, opposing_arguments)\n",
        "        st.markdown(f\"**Common Ground Identified:** {common_ground}\")\n",
        "\n",
        "        ## Step 8: Generating Final Insight ##\n",
        "        with st.spinner(\"Creating final insight...\"):\n",
        "            final_insight = generate_final_insight(common_ground)\n",
        "        st.subheader(\"Final Insight\")\n",
        "        st.markdown(f\"{final_insight}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDlxmUqqYdHr",
        "outputId": "2cbe603b-f1ae-4342-e81a-5fc084d6f3be",
        "collapsed": true
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting discoursedecoder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!npm install localtunnel\n",
        "!npm audit fix --force"
      ],
      "metadata": {
        "id": "5jDPqmRSYicD",
        "collapsed": true
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -q -O - ipv4.icanhazip.com\n",
        "!streamlit run discoursedecoder.py &>/content/logs.txt &\n",
        "! npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lHFdJTT57s6",
        "outputId": "d0bd0797-c5e9-4d50-ecac-a9723d2a1ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.168.225.24\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://short-shrimps-hear.loca.lt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}